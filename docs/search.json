[
  {
    "objectID": "What_makes_a_good_systematic_review.html",
    "href": "What_makes_a_good_systematic_review.html",
    "title": "What makes a ‘good’ systematic evidence synthesis?",
    "section": "",
    "text": "TL;DR\n\n\n\nThere are lots of “bad” evidence syntheses published but what makes a “good” one and how can we spot them?"
  },
  {
    "objectID": "What_makes_a_good_systematic_review.html#what-makes-a-good-systematic-evidence-synthesis",
    "href": "What_makes_a_good_systematic_review.html#what-makes-a-good-systematic-evidence-synthesis",
    "title": "What makes a ‘good’ systematic evidence synthesis?",
    "section": "1 What makes a good systematic evidence synthesis?",
    "text": "1 What makes a good systematic evidence synthesis?\nThere has been an proliferation of studies claiming to be systematic evidence syntheses. Many of these studies are of poor quality and have a high risk of bias. Systematic evidence synthesis strives to reduce bias and poor quality syntheses could be misleading and waste valuable resources. As pointed out by Haddaway et al. (2020) these poor quality syntheses could be eroding trust in “evidence synthesis as an academic endeavour”. I would go as far as to suggest that they are eroding trust in evidence synthesis.\n\n1.1 Identifying a good evidence synthesis\nHere are some simple criteria to help you identify a good synthesis:\n\n1.1.1 A Clear Research Question:\nA good synthesis has a well-defined research question that guides the entire review process. Often a good synthesis will use a question formulation framework/tool to help them identify the key elements. For example, a common approach is to identify the PICO elements of a question; Population, Intervention, Control, Outcome.\n\n\n1.1.2 Transparent Methods:\nLook for transparency in the methodology section. A good synthesis should clearly outline its search strategy, inclusion and exclusion criteria, data extraction methods, and quality assessment criteria. A predefined (before the work started on the synthesis) protocol outlining the steps and decisions to be made adds to trust in the evidence synthesis. This avoids “mission creep” where the question changes to fit the evidence found and not to answer the original question.\n\n\n1.1.3 Comprehensive Search Strategy:\nA comprehensive search strategy is essential to ensure that all relevant studies are identified. Look for details on the databases searched, search terms used, and any other sources consulted (e.g., grey literature, conference proceedings). Multiple databases should be searched and unpublished (i.e. grey literature) sources should be consulted.\n\n\n1.1.4 Inclusion Criteria:\nEnsure that the synthesis clearly states the criteria used to include or exclude studies. This helps in understanding the scope of the synthesis and the generalisability of its findings.\n\n\n1.1.5 Quality Assessment:\nLook for information on how the quality of included studies was assessed. This could involve evaluating study design, risk of bias, and other relevant factors. This is a vital element that is often missed.\n\n\n1.1.6 Data Synthesis:\nA good synthesis should provide a clear synthesis of the evidence, including any statistical analysis or qualitative synthesis methods used. Open data and open code, where appropriate, should be available to readers.\n\n\n1.1.7 Risk of Bias Assessment:\nThe synthesis should address the risk of bias in the included studies. Look for methods used to minimise bias and consider how potential biases might impact the review findings. Risk of bias are things in the conduct of a study that could lead to misleading results. For example a small sample size might mean a study does not have enough statistical power to determine the size or direction of an effect.\n\n\n1.1.8 Discussion of Limitations:\nA good synthesis should discuss its limitations openly. This could include limitations related to the search strategy, study quality, or other factors that may impact the validity of the findings.\n\n\n1.1.9 Conclusion Supported by Evidence:\nEnsure that the conclusions drawn in the synthesis are supported by the evidence presented. Look for consistency between the findings and the data synthesised from the included studies. Do not just rely on the abstract or the lay summary.\n\n\n\n1.2 Conclusion\nBy carefully assessing these criteria, you can better distinguish between good and bad syntheses and make more informed decisions about their reliability and validity.\nDonnelly et al. (2018) provided a much simpler schema which condenses the criteria above in to four principles - Inclusive, Rigorous, Transparent and Accessible.\n\n\n\nFigure from Donnelly et al. (2018) Four principles to make evidence synthesis more useful for policy\n\n\nIt is not easy identifying good evidence synthesis. Sometimes the criteria/principles outlined above are hard to identify. It can be tough to know if a synthesis only achieves some of the criteria how much it can be trusted.\nThere are many organisations whose purpose it is to help produce and share robust, high quality evidence syntheses. In the environmental field there is The Collaboration for Environmental Evidence. If you need help please reach out.\n\n\n\n\n\n\nAcknowledgements"
  },
  {
    "objectID": "Publications.html",
    "href": "Publications.html",
    "title": "Publications",
    "section": "",
    "text": "The full list of my publications can be found on GoogleScholar. If you can not find an open access version of any of my publications please get in contact and I will send you one.\n\n\n\n\n\nauthor\nyear\ntitle\njournal\nnumber\n\n\n\n\nEB Nilsen, M Grainger, FT Singsaas, T Simensen, H Stokland, T Sutcliffe\n2024\nStudy protocol for the systematic map\" Effects of land use and land cover changes on biodiversity, ecosystem services, and carbon storage in Norway: A systematic map and …\nOSF\n\n\n\nM Evju, M Grainger, U Jansson, SL Olsen, RE Roos, O Skarpaas, ...\n2024\nOvervåking av dragehode Dracocephalum ruyschiana. Årsrapport 2023\nNorsk institutt for naturforskning (NINA)\n\n\n\nS Nakagawa, ER Ivimey-Cook, MJ Grainger, RE O’Dea, S Burke, ...\n2023\nMethod Reporting with Initials for Transparency (MeRIT) promotes more granularity and accountability for author contributions\nnature communications\n14 (1), 1788\n\n\nPHP Braga, K Hébert, EJ Hudgins, ER Scott, BPM Edwards, ...\n2023\nNot just for programmers: How GitHub can accelerate collaborative and reproducible research in ecology and evolution\nMethods in Ecology and Evolution\n14 (6), 1364-1380\n\n\nER Ivimey‐Cook, JL Pick, KR Bairos‐Novak, A Culina, E Gould, ...\n2023\nImplementing code review in the scientific workflow: Insights from ecology and evolutionary biology\nJournal of evolutionary biology\n36 (10), 1347-1356\n\n\nSJ Cooke, CN Cook, VM Nguyen, JC Walsh, N Young, C Cvitanovic, ...\n2023\nEnvironmental evidence in action: on the science and practice of evidence synthesis and evidence-based decision-making\nEnvironmental Evidence\n12 (1), 10\n\n\nG Saridnirun, N Sukumal, MJ Grainger, T Savini\n2023\nLow-intensive agricultural landscapes could help to sustain Green Peafowl Pavo muticus inhabiting surrounding forest patches in Northern Thailand\nGlobal Ecology and Conservation\n44, e02487\n\n\nNM Shwe, M Grainger, D Ngoprasert, SS Aung, M Grindley, T Savini\n2023\nAnthropogenic pressure on large carnivores and their prey in the highly threatened forests of Tanintharyi, southern Myanmar\nOryx\n57 (2), 262-271\n\n\nE Durrant, P Howson, B Puttick, S Potts, Y Shennan-Farpón, N Sari, ...\n2023\nExisting evidence on the use of participatory scenarios in ecological restoration: a systematic map\nEnvironmental Evidence\n12 (1), 27\n\n\nJL Gan, MJ Grainger, MDF Shirley, M Pfeifer\n2023\nHow effective are perches in promoting bird-mediated seed dispersal for natural forest regeneration? A systematic review protocol\nEnvironmental Evidence\n12 (1), 15\n\n\nS Nybø, A Kolstad, H Sandvik, V Bakkestuen, M Evju, E Framstad, ...\n2023\nIndikatorer for økologisk tilstand i våtmark, semi-naturlig mark og naturlig åpne områder under skoggrensa\nNorsk institutt for naturforskning (NINA)\n\n\n\nCR Nater, SP Hofhuis, M Grainger, D Ehrich\n2023\nStatistiske verktøy for prediksjon av årlig bestandsvekst og effekter av jakt på rødrev\nNorsk institutt for naturforskning (NINA)\n\n\n\nM Evju, M Grainger, SL Olsen, RE Roos, O Skarpaas, OE Stabbetorp\n2023\nOvervåking av dragehode Dracocephalum ruyschiana i 2022. Resultater og forslag til veien videre\nNorsk institutt for naturforskning (NINA)\n\n\n\nNR Haddaway, MJ Grainger, CT Gray\n2022\nCitationchaser: A tool for transparent and efficient forward and backward citation chasing in systematic searching\nResearch Synthesis Methods\n13 (4), 533-545\n\n\nRJ Boyd, GD Powney, F Burns, A Danet, F Duchenne, M Grainger, ...\n2022\nROBITT: a tool for assessing the risk‐of‐bias in studies of temporal trends in ecology\nMethods in Ecology and Evolution\n\n\n\nS Piras, S Righi, M Setti, N Koseoglu, MJ Grainger, GB Stewart, M Vittuari\n2022\nFrom social interactions to private environmental behaviours: The case of consumer food waste\nResources, Conservation and Recycling\n176, 105952\n\n\nAP Christie, H Downey, WF Frick, M Grainger, D O'Brien, ...\n2022\nA practical conservation tool to combine diverse types of evidence for transparent evidence‐based decision‐making\nConservation Science and Practice\n4 (1), e579\n\n\nMS Reed, DM Young, NG Taylor, R Andersen, NGA Bell, H Cadillo-Quiroz, ...\n2022\nPeatland core domain sets: building consensus on what should be measured in research and monitoring\nMires and Peat\n28, 26\n\n\nE Moore, P Howson, M Grainger, YA Teh, M Pfeifer\n2022\nThe role of participatory scenarios in ecological restoration: a systematic map protocol\nEnvironmental Evidence\n11 (1), 23\n\n\nM Grainger, NR Haddaway\n2022\nWhy “vote-counting” is never acceptable in evidence synthesis\nOSF\n\n\n\nHE Marshall, M Grainger, N Sukumal, T Savini\n2022\nThe threat of free-ranging domestic dog to native wildlife: implication for conservation in Southeast Asia\n\n\n\n\nD Hagen, AC Mehlhoop, E Torsæter, MO Kyrkjeeide, MJ Grainger, M Evju\n2022\nAssessing the effect of mitigation efforts to improve vegetation recovery in powerline construction sites across Norway\nEcological Engineering\n184, 106789\n\n\nG Gupta, M Grainger, JC Dunn, R Sanderson, PJK McGowan\n2022\nConservation of Galliformes in the Greater Himalaya: is there a need for a higher-quality evidence-base?\nBird Conservation International\n32 (3), 360-369\n\n\nNR Haddaway, A Bannach-Brown, MJ Grainger, WK Hamilton, ...\n2022\nThe evidence synthesis and meta-analysis in R conference (ESMARConf): levelling the playing field of conference accessibility and equitability\nSystematic Reviews\n11 (1), 113\n\n\nM Evju, RE Roos, A Endrestøl, M Nowell, O Hanssen, EE Ombler\n2022\nEffektovervåking av trua arter og naturtyper 2022\nNorsk institutt for naturforskning (NINA)\n\n\n\nJJ Cusack, EB Nilsen, MF Israelsen, H Andrén, M Grainger, JDC Linnell, ...\n2022\nQuantifying the checks and balances of collaborative governance systems for adaptive carnivore management\nJournal of Applied Ecology\n\n\n\nT Amano, L Bako, M Best, N Boenisch, P Boersch-Supan, D Browne, ...\n2022\nTransforming practice: checklists for delivering change\nOpen Book Publishers\n\n\n\nWJ Sutherland, T Amano, N Boenisch, SH Cheng, AP Christie, ...\n2022\nPresenting Conclusions from Assessed Evidence\nTransforming Conservation. A Practical Guide to Evidence and Decision Making\n\n\n\nH Downey, T Amano, M Cadotte, CN Cook, SJ Cooke, NR Haddaway, ...\n2021\nTraining future generations to deliver evidence‐based conservation and ecosystem management\nEcological Solutions and Evidence\n2 (1), e12032\n\n\nL Aramyan, M Grainger, K Logatcheva, S Piras, M Setti, G Stewart, ...\n2021\nFood waste reduction in supply chains through innovations: a review\nMeasuring Business Excellence\n25 (4), 475-492\n\n\nG Saridnirun, N Sukumal, MJ Grainger, T Savini\n2021\nLiving with human encroachment: Status and distribution of Green Peafowl in northern stronghold of Thailand\nGlobal Ecology and Conservation\n28, e01674\n\n\nNR Haddaway, CT Gray, M Grainger\n2021\nNovel tools and methods for designing and wrangling multifunctional, machine-readable evidence synthesis databases\nEnvironmental Evidence\n10 (1), 5\n\n\nM Crane, I Silva, MJ Grainger, GA Gale\n2021\nLimitations and gaps in global bat wing morphology trait data\nMammal Review\n\n\n\nJ Cusack, EB Nilsen, MF Israelsen, H Andrén, M Grainger, JDC Linnell, ...\n2021\nQuantifying the checks and balances of decentralised governance systems for adaptive carnivore management\nEcoEvoRxiv\n\n\n\nG Gupta, M Grainger, JC Dunn, R Sanderson, PJK McGowan\n2021\nWhat is the evidence available to support our knowledge about threats to the conservation of Galliformes in the Greater Himalaya?\nbioRxiv\n2021.02. 23.432604\n\n\nM Evju, SL Olsen, O Skarpaas, OE Stabbetorp\n2021\nOvervåking av dragehode Dracocephalum ruyschiana. Beskrivelse av metodikk og resultater 2017‒2020\nNorsk institutt for naturforskning (NINA)\n\n\n\nB Cretois, JDC Linnell, M Grainger, EB Nilsen, JK Rød\n2020\nHunters as citizen scientists: Contributions to biodiversity monitoring in Europe\nGlobal Ecology and Conservation\n23, e01077\n\n\nMJ Grainger, FC Bolam, GB Stewart, EB Nilsen\n2020\nEvidence synthesis for tackling research waste\nNature Ecology & Evolution\n4 (4), 495-497\n\n\nW Phumanee, R Steinmetz, R Phoonjampa, T Bejraburnin, M Grainger, ...\n2020\nOccupancy‐based monitoring of ungulate prey species in Thailand indicates population stability, but limited recovery\nEcosphere\n11 (9), e03208\n\n\nTNE Gray, MJ Grainger, R Grosu\n2020\nConservation decision‐making under uncertainty: Identifying when to reintroduce tiger Panthera tigris to Cambodia\nConservation Science and Practice\n2 (7), e187\n\n\nC Kandemir, C Reynolds, M Verma, M Grainger, G Stewart, S Righi, ...\n2020\nModelling Approaches to Food Waste: Discrete event simulation; machine learning; Bayesian networks; agent-based modelling; and mass balance estimation\nRoutledge Handbook of Food Waste\n326-344\n\n\nL Braunholtz, M Grainger, M Pfeifer\n2020\nHow have roads changed tropical terrestrial biodiversity? Protocol for a system-atic review and meta-analysis-version 2\n\n\n\n\nC Kandemier, C Reynolds, M Verma, M Grainger, G Stewart, S Righi, ...\n2020\nModelling approaches to food waste: discrete event simulation; machine learning; Bayesian networks; agent-based modelling; and mass balance estimation.\nIn: Reynolds, C., Soma, T., Spring, C. & Lazell, J.(eds.). Routledge …\n\n\n\nFC Bolam, MJ Grainger, KL Mengersen, GB Stewart, WJ Sutherland, ...\n2019\nUsing the value of information to improve conservation decision making\nBiological Reviews\n94 (2), 629-647\n\n\nNR Haddaway, A Feierman, MJ Grainger, CT Gray, E Tanriver-Ayder, ...\n2019\nEviAtlas: a tool for visualising evidence synthesis databases\nEnvironmental Evidence\n8, 1-10\n\n\nJ Carrick, MSAB Abdul Rahim, C Adjei, HHH Ashraa Kalee, SJ Banks, ...\n2019\nIs planting trees the solution to reducing flood risks?\nJournal of Flood Risk Management\n12 (S2), e12484\n\n\nMJ Grainger, S Piras, S Righi, M Setti, GB Stewart, M Vittuari\n2019\nBehavioural economics: Linking Bayesian and agent-based models to assess consumer food waste.\nHorizon\n2020 REFRESH website.\n\n\nB Freeman, D Jiménez-García, B Barca, M Grainger\n2019\nUsing remotely sensed and climate data to predict the current and potential future geographic distribution of a bird at multiple scales: the case of Agelastes meleagrides, a …\nAvian Research\n10, 1-9\n\n\nN SUKUMAL, MJ GRAINGER, T SAVINI\n2019\nLower levels of human disturbance correspond with longer-term persistence of Endangered Green Peafowl Pavo muticus populations\nBird Conservation International\n1-10\n\n\nMJ Whittingham, AJ McKenzie, RM Francksen, D Feige, T Cadwallender, ...\n2019\nOffshore refuges support higher densities and show slower population declines of wintering Ruddy Turnstones Arenaria interpres\nBird study\n66 (4), 431-440\n\n\nM Grainger, FC Bolam, GB Stewart, EB Nilsen\n2019\nMaximising the leverage of existing knowledge could reduce research waste in applied ecology and conservation\n\n20th Sept\n\n\nM Grainger, S Piras, S Righi, M Setti, G Stewart, M Vittuari\n2019\nIntegrated model of consumer behaviours in relation to food waste: Behavioural economics: D4. 4 Linking Bayesian and agent-based models to assess consumer food waste\nRefresh\n\n\n\nM Grainger, EB Nilsen\n2019\nNeed for transparent and repeatable conservation frameworks: reply to Child et al. 2019\n\n\n\n\nPJK McGowan, GB Stewart, G Long, MJ Grainger\n2018\nAn imperfect vision of indivisibility in the Sustainable Development Goals\nNature Sustainability\n1 (12)\n\n\nMJ Grainger, L Aramyan, K Logatcheva, S Piras, S Righi, M Setti, ...\n2018\nThe use of systems models to identify food waste drivers\nGlobal food security\n16, 1-8\n\n\nMJ Grainger, L Aramyan, S Piras, TE Quested, S Righi, M Setti, M Vittuari, ...\n2018\nModel selection and averaging in the assessment of the drivers of household food waste to reduce the probability of false positives\nPloS one\n13 (2), e0192075\n\n\nH Kendall, G Kaptan, G Stewart, M Grainger, S Kuznesof, P Naughton, ...\n2018\nDrivers of existing and emerging food safety risks: Expert opinion regarding multiple impacts\nFood Control\n90, 440-458\n\n\nMJ Grainger, PJ Garson, SJ Browne, PJK McGowan, T Savini\n2018\nConservation status of phasianidae in Southeast Asia\nBiological Conservation\n220, 60-66\n\n\nF Stephenson, AC Mill, CL Scott, GB Stewart, MJ Grainger, NVC Polunin, ...\n2018\nSocio-economic, technological and environmental drivers of spatio-temporal changes in fishing pressure\nMarine Policy\n88, 189-203\n\n\nS Thunhikorn, MJ Grainger, PJK McGowan, T Savini\n2018\nSpatial distribution of display sites of Grey Peacock-pheasant in relation to micro-habitat and predators during the breeding season\nAvian Research\n9, 1-12\n\n\nG Matthew, S Gavin, S Piras, S Righi, M Setti, M Vittuari\n2018\nModel integration. Integrated socio-economic model on food waste\nNewcastle University\n\n\n\nMJ Grainger, GB Stewart\n2017\nThe jury is still out on social media as a tool for reducing food waste a response to Young et al.(2017)\nResources, Conservation and Recycling\n122, 407-410\n\n\nM Grainger, D Ngoprasert, P McGowan, T Savini\n2017\nInforming decisions on an extremely data poor species facing imminent extinction\nOryx\n\n\n\nLH Aramyan, MJ Grainger, K Logatcheva, S Piras, S Righi, M Setti, ...\n2017\nFood Waste Reduction in Supply Chains Through Innovations: What Factors Affect the Decision to Adopt Innovations\nThe\n24th IAMB Conference\n\n\nM Grainger, G Stewart, S Piras, S Righi, M Setti, M Vittuari, LH Aramyan\n2017\nD4. 3-Model integration: integrated socio-economic model on food waste\nREFRESH\n\n\n\nS Thunhikorn, MJ Grainger, PJK McGowan, T Savini\n2016\nMethods used to survey avian species and their potential for surveying ground-dwelling birds in Asia\nForktail\n32, 5-13\n\n\nM Grainger, G Stewart, S Piras, S Righi, M Setti, M Vittuari, LH Aramyan\n2016\nD4. 2-Model development and data protocol\nREFRESH\n\n\n\nS Thunhikorn, MJ Grainger, PJK McGowan, T Savini\n2016\nAssessing the population of grey peacock-pheasant (Polyplectron bicalcaratum) in a Southeast Asian conservation landscape\nRAFFLES BULLETIN OF ZOOLOGY\n64, 302-312\n\n\nM Grainger, GS Crichton, S Piras, S Righi, M Setti, M Vittuari\n2016\nModel Development and Data Protocol\nNewcastle University\n\n\n\nM Grainger, G Stewart, S Piras, S Righi, M Setti, M Vittuari\n2016\nAcknowledgments & Disclaimer\n\n\n\n\nG Matthew, CG STEWART, P Simone, S Righi, V Matteo\n2016\nModel Development and Data Protocol\nWageningen University\n\n\n\nS Thunhikorn, MJ Grainger, PJK McGowan, T Savini\n2016\nAssessing the population status of Grey Peacock-pheasant (Polyplectron bicalcaratum) in Huai Kha Khaeng, a key conservation landscape in Southeast Asia\nRaffles Bulletin of Zoology\n\n\n\nIUCN Species Survival Commission\n2015\nAn IUCN situation analysis of terrestrial and freshwater fauna in West and Central Africa\nIUCN\n\n\n\nFHA Aalen, MJ Grainger, F Hibert, M Hoffmann, DP Mallon, ...\n2015\nAnalyse de situation de l'UICN concernant la faune terrestre et d'eau douce en Afrique centrale et de l'Ouest\nIUCN\n\n\n\nM Grainger, R van Aarde\n2015\nCan non-native species explain patterns of convergence and deviation in regenerating coastal dune forest?\nEcological Restoration\n33 (3), 246-255\n\n\nMJ Grainger, RJ Van Aarde\n2013\nThe role of canopy gaps in the regeneration of coastal dune forest\nAfrican Journal of Ecology\n51 (1), 11-20\n\n\nM Grainger, P McGowan, A McKenzie, J Minderman, JP Rodriguez, ...\n2013\nMETHOD FOR THE ASSESSMENT OF PRIORITIES FOR INTERNATIONAL SPECIES CONSERVATION (MAPISCo)\n\n\n\n\nPJK McGowan, LL Owens, MJ Grainger\n2012\nGalliformes science and species extinctions: what we know and what we need to know\nAnimal Biodiversity and Conservation\n35 (2), 321-331\n\n\nMJ Grainger, RJ Van Aarde\n2012\nIs succession-based management of coastal dune forest restoration valid?\nEcological Restoration\n30 (3), 200-208\n\n\nRAR Guldemond, MJ Grainger, MJ Trimble\n2012\nWhere is the Evidence for Assessing Evidence‐Based Restoration? Comments on Ntshotsho et al.(2010)\nRestoration Ecology\n20 (1), 7-9\n\n\nMJ Grainger, RJ van Aarde, TD Wassenaar\n2011\nLandscape composition influences the restoration of subtropical coastal dune forest\nRestoration Ecology\n19 (101), 111-120\n\n\nMJ Grainger\n2011\nAn evaluation of coastal dune forest restoration in northern KwaZulu-Natal, South Africa\nUniversity of Pretoria\n\n\n\nMJ Grainger, RJ Van Aarde\n2011\nResilience of the medicinal plant community of rehabilitating coastal dune forests, KwaZulu-Natal, South Africa\nWiley-Blackwell\n\n\n\nC Bonnington, M Grainger, S Dangerfield, E Fanning\n2010\nThe influence of electric fences on large mammal movements in the Kilombero Valley, Tanzania.\nAfrican Journal of Ecology\n48 (1)\n\n\nC Bonnington, MD Steer, J Lamontagne-Godwin, N Owen, M Grainger\n2010\nEvidence for local declines in Tanzania’s puku antelope (Kobus vardoni Livingstone, 1857) population between 1999 and 2003\nAfrican Journal of Ecology\n48 (4), 1139-1142\n\n\nM Grainger, R van Aarde, I Whyte\n2005\nLandscape heterogeneity and the use of space by elephants in the Kruger National Park, South Africa\nAfrican Journal of Ecology\n43 (4), 369-375\n\n\nG Stewart, F Bolam, B Clark, M Grainger\nNA\nIs Planting Trees the Solution to Reducing Flood Risks?"
  },
  {
    "objectID": "OpenAlex.html",
    "href": "OpenAlex.html",
    "title": "Using OpenAlex to get publication metadata",
    "section": "",
    "text": "I have been playing around with the OpenAlexR package which interfaces with the OpenAlex API. This allows you to get bibliographic information about publications, authors, institutions, sources, funders, publishers, topics and concepts.\nHere I first look at the proportion of open publications published by NINA over time.\nlibrary(openalexR, quietly = TRUE)\nlibrary(tidyverse, quietly = TRUE)\noa_fetch( entity = \"inst\", # same as \"institutions\" \n          display_name.search = \"\\\"Norwegian Institute for Nature\\\"\") |&gt; \n  select(display_name, ror) |&gt;  \n  knitr::kable()\n\n\n\n\ndisplay_name\nror\n\n\n\n\nNorwegian Institute for Nature Research\nhttps://ror.org/04aha0598\nAll_NINA&lt;- oa_fetch( entity = \"works\", institutions.ror = \"04aha0598\", type = \"article\", from_publication_date = \"2000-01-01\", is_paratext = \"false\" )\n\n# Get the open records\n\nopen_access &lt;- oa_fetch( entity = \"works\", institutions.ror = \"04aha0598\", type = \"article\", from_publication_date = \"2000-01-01\", is_paratext = \"false\", is_oa = \"true\", group_by = \"publication_year\" )\n# Get the closed records\nclosed_access &lt;- oa_fetch( entity = \"works\", institutions.ror = \"04aha0598\", type = \"article\", from_publication_date = \"2000-01-01\", is_paratext = \"false\", is_oa = \"false\", group_by = \"publication_year\" )\n# Join the dataframes together\nuf_df &lt;- closed_access |&gt;  \n  select(- key_display_name) |&gt;  \n  full_join(open_access, by = \"key\", suffix = c(\"_ca\", \"_oa\"))\nuf_df  |&gt;  filter(key &lt;= 2024) |&gt; # we do not yet have complete data for 2024\n  pivot_longer(cols = starts_with(\"count\"))  |&gt; \n  mutate( year = as.integer(key), is_oa = recode( name, \"count_ca\" = \"Closed Access\", \"count_oa\" = \"Open Access\" ), label = if_else(key &lt; 2024, NA_character_, is_oa) )  |&gt; \n  select(year, value, is_oa, label)  |&gt; \n  ggplot(aes(x = year, y = value, group = is_oa, color = is_oa)) + \n  geom_line(size = 1) + \n  labs( title = \"NINA's progress towards Open Access\", x = NULL, y = \"Number of journal articles\") +\n  scale_color_brewer(palette = \"Dark2\", direction = -1) +\n  scale_x_continuous(breaks = seq(2000, 2024, 2)) + \n  geom_text(aes(label = label), nudge_x = -5, hjust = 0) + \n  coord_cartesian(xlim = c(NA, 2024.5)) + \n  guides(color = \"none\")+ \n  ggthemes::theme_solarized()"
  },
  {
    "objectID": "OpenAlex.html#extract-the-topics",
    "href": "OpenAlex.html#extract-the-topics",
    "title": "Using OpenAlex to get publication metadata",
    "section": "1 Extract the topics",
    "text": "1 Extract the topics\nThe “topic” for each record is a description of the subject matter of the publication determined by using a large language model. The example from the OpenAlex topics page is:\nExample Topic: “Artificial Intelligence in Medicine” Domain: “Health Sciences” Field: “Medicine” Subfield: “Health Informatics”\nEach topic is made up of a subfield, a field and a domain. The model scores each documents topics, with the highest topic score being considered the “primary” topic.\n\n1.1 All topics\n\nexpanded_tibble &lt;- All_NINA |&gt;  # Unnest the 'topics' to duplicate each row for each topic \n  unnest(topics, names_sep = \"_\")  |&gt; \n  select(display_name, everything())\n\nword_df&lt;-expanded_tibble |&gt; \n  group_by(topics_display_name) |&gt; \n  tally()\n\nwordcloud2::wordcloud2(word_df)\n\n\n\n\n\n\n\n\n1.2 Primary topics\n\nget_top_topic &lt;- function(df) {\n  if (nrow(df) == 0 || sum(df$name == \"topic\") == 0) {\n    # If the dataframe is empty or contains no topics\n    return(data.frame(display_name = NA, score = NA))\n  } else {\n    # Otherwise, proceed to get the top topic\n    top_topic &lt;- df  |&gt; \n      filter(name == \"topic\")  |&gt; \n      slice_max(order_by = score)  |&gt; \n      slice_head(n = 1)  # Ensure only one result is returned\n    return(top_topic)\n  }\n}\n\ntop_topics&lt;-All_NINA  |&gt; \n  mutate(\n    top_topic_display_name = map_chr(topics, ~ {\n      result &lt;- get_top_topic(.x)\n      if (nrow(result) &gt; 0) result$display_name else NA\n    }),\n    top_topic_score = map_dbl(topics, ~ {\n      result &lt;- get_top_topic(.x)\n      if (nrow(result) &gt; 0) result$score else NA\n    })\n  )\n\n\ntopics_df&lt;-top_topics |&gt; \n  group_by(top_topic_display_name) |&gt; \n  tally()\n\nwordcloud2::wordcloud2(topics_df)"
  },
  {
    "objectID": "listing.html",
    "href": "listing.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n\n\n\n\n  \n\n\n\n\nDr Matthew J Grainger\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nESHackathon: Unlocking Evidence Synthesis Through Innovation!\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nLeveraging Open Source Tools for accelerating Evidence Synthesis\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nMaking missing data work for us\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPublications\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nSmall data in ecology\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nUsing OpenAlex to get publication metadata\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nWhat makes a ‘good’ systematic evidence synthesis?\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nWhich shortcuts are really shortcuts in systematic reviews?\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "ESHackathon.html",
    "href": "ESHackathon.html",
    "title": "ESHackathon: Unlocking Evidence Synthesis Through Innovation!",
    "section": "",
    "text": "Embark on an innovative journey with ESHackathon – where our workshops promote inclusive dynamic spaces for collaboration in evidence synthesis.\nOriginating as an open software development event in 2018, ESHackathon has evolved into a conference, training courses and hackathons, uniting diverse talents to tackle complex challenges in identifying and summarising evidence.\n\n0.1 Why is Technology Vital for Evidence Synthesis?\nIn a world of constantly expanding literature, ESTech revolutionises the way we synthesise the literature. Through text analysis, machine learning, and collaborative coding, we automate tasks, cut costs, and enhance global accessibility, making rigorous evidence synthesis efficient.\n\n\n0.2 Hackathon Highlights:\n\n\nDiverse Participation: All are welcome - coders, health researchers, environmental scientists, social scientists, statisticians and more!\n\n\nProblem-Solving: It’s not just for programmers! Combine technology and evidence synthesis expertise to develop novel frameworks and tackle fundamental evidence synthesis challenges.\n\n\nGlobal Collaboration: Unite with talents worldwide to create impactful solutions for evidence synthesis challenges.\n\n\n\n\n0.3 Get Involved:\n\n\nStay Connected: Follow us for updates and details at  https://www.eshackathon.org/ \n\n\nSign-up for Courses: Elevate your skills with our evidence synthesis training courses https://opencollective.com/esmarconf/events \n\n\nRelive ESMARConf: Revisit the experience with all sessions available forever on YouTube https://esmarconf.org/recordings  \n\nGet in contact with us if you have a need for bespoke evidence synthesis solutions eshackathon@gmail.com \nESHackathon relies on generous funding from our supporters to progress our goals of making evidence synthesis faster, cheaper, and more reliable. If you are interested in supporting our activities then please donate here https://opencollective.com/esmarconf/contribute \n\n\n\n0.4 ESHackathon Project Highlights\nParticipants in ESH have produced 11 fully functional tools, many of which have non-coding user interfaces. Tools include:\n\ncitationchaser - conducts forward and backward citation chasing for systematic searching\nEviAtlas - creates interactive visualisations of geographical evidence map data\nrobvis - visualises risk of bias assessments\nmetafor::reports - produces methods and results text based on meta-analytic model inputs\nsysrevdata - converts between evidence synthesis database formats (long, wide, condensed)\nPRISMA2020 - produces PRISMA-compliant flow diagrams (&gt;6000 monthly users)\nROSESflowchart - produces ROSES-compliant flow diagrams\nbibfix - corrects and compiles bibliographic files\nmetadat - an R repository of meta-analytic datasets\nPredicTER - estimates the time requirement for evidence synthesis projects\n\nWe have also published 8 academic papers as a result of ESH working group discussions, with several more in preparation:\n\nNakagawa, Shinichi, et al. “A new ecosystem for evidence synthesis.” Nature Ecology & Evolution 4.4 (2020): 498-501\nHaddaway, Neal R., et al. “The evidence synthesis and meta-analysis in R conference (ESMARConf): levelling the playing field of conference accessibility and equitability.” Systematic Reviews 11.1 (2022): 1-9.\nHaddaway, Neal R., et al. “EviAtlas: a tool for visualising evidence synthesis databases.” Environmental Evidence 8.1 (2019): 1-10.\nHaddaway, Neal R., and Martin J. Westgate. “Creating and curating a community of practice: introducing the evidence synthesis Hackathon and a special series in evidence synthesis technology.” Environmental Evidence 9.1 (2020): 1-4.\nHaddaway, Neal R., Matthew J. Grainger, and Charles T. Gray. “Citationchaser: A tool for transparent and efficient forward and backward citation chasing in systematic searching.” Research Synthesis Methods 13.4 (2022): 533-545.\nHaddaway, Neal R., Charles T. Gray, and Matthew Grainger. “Novel tools and methods for designing and wrangling multifunctional, machine-readable evidence synthesis databases.” Environmental Evidence 10.1 (2021): 5.\nHennessy, Emily A., et al. “Ensuring prevention science research is synthesis-ready for immediate and lasting scientific impact.” Prevention Science 23.5 (2022): 809-820.\nHaddaway, Neal R., et al. “PRISMA2020: An R package and Shiny app for producing PRISMA 2020‐compliant flow diagrams, with interactivity for optimised digital transparency and Open Synthesis.” Campbell Systematic Reviews 18.2 (2022): e1230."
  },
  {
    "objectID": "Ecology_SR.html",
    "href": "Ecology_SR.html",
    "title": "Which shortcuts are really shortcuts in systematic reviews?",
    "section": "",
    "text": "TL;DR\n\n\n\nReviews in ecology often take short-cuts in the review process - the effect this has on the risk of bias is unknown and could be quite severe. A recent paper showed (in health) that some short-cuts can be carried out with minimal effect on the review. Many ecological reviews make short-cuts that can actually increase the risk of bias.\nThis post was inspired by the recent ESHackathon event hosted by the Innovation Observatory at Newcastle University where one of the projects was to update PredicTER so that we can predict the potential time saving of different common short-cuts used in rapid reviews."
  },
  {
    "objectID": "Ecology_SR.html#rapid-reviews",
    "href": "Ecology_SR.html#rapid-reviews",
    "title": "Which shortcuts are really shortcuts in systematic reviews?",
    "section": "1 Rapid reviews",
    "text": "1 Rapid reviews\nThere is a clear demand from policy-makers for rapid evidence synthesis. “Rapid Reviews” are a type of systematic review where one or more of the review processes are simplified, sped-up (through, for example, AI tools to assist screening) or completely omitted. There is not a unified definition of what a “Rapid Review” is, and authors tend to take different “short-cuts” depending on resource constraints or the knowledge/experience of the review team.\nA paper published in Research Synthesis Methods, Haby et al. (2023) addresses this heterogeneity in short-cuts used for Rapid Review and assess where possible the evidence about the risk of bias associated with each.\nHaby et al. (2023) provide a really useful guide to what short-cuts one can take in a Rapid Review. Their Table 2 (recreated below) lists each commonly used short-cut and the potential impact on the risk of bias.\n\nTable 1. The potential risk of bias for each short-cut as shown by Haby et al. (2023) in their Table 2.\n\n\n\n\n\n\n\n\nPossible “short-cuts” categorised by review step\nRecommended (yes/no)\nPotential impact on risk of bias if done\nSupporting evidence within Haby et al.\n\n\n\n\nPreparation of a protocol\n\n\n\n\n\nOmit protocol\nNo\n↑\n✗\n\n\nPrepare a protocol and make publicly available (e.g., PROSPERO or Open Science Framework). Limit included information to the key aspects that allow a complete assessment of risk of bias (with AMSTAR 2 or ROBIS).\nYes\n↓\n✗\n\n\nQuestion formulation\n\n\n\n\n\nLimit the number of questions and sub-questions and limit the scope of the question/s\nYes\nNone expected\n✗\n\n\nLimit the number of outcomes\nYes\nNone expected\n✗\n\n\nInclusion criteria\n\n\n\n\n\nLimit publication language to English but provide justification\nYes\nMinimal\n✓\n\n\nExclude gray/unpublished literature but provide justification and note that it may lead to an overestimation of effect\nYes\nMinimal\n✓\n\n\nRestrictions based on publication date, for example, last 5, 1 , or 2  years (unless it is known that relevant studies could only have been reported since a specific date)\nNo\n↑\n✓\n\n\nLimit to papers available electronically\nNo\n↑\n✓\n\n\nRestrict study types to systematic reviews\nYes\nNone expected\n✗\n\n\nRestrict study types to randomized controlled trials or controlled clinical trials\n\n\n\n\n\nSearching\n\n\n\n\n\nUse of a single database for searching (e.g., PubMed)\nNo\n↑\n✓\n\n\nLimit number of databases searched to at least two and one supplementary source (e.g., reference lists of included studies). If searching for RCTs search Medline/PubMed, EMBASE, and CENTRAL).\nYes\nNone\n✓\n\n\nUse the Polyglot Search Translator to translate search strings across multiple databases, though noting its limitations: https://sr-accelerator.com/#/help/polyglot\nYes\nNone\n✓\n\n\nUse of the Cochrane RCT Classifier for systematic reviews of RCTs to reduce screening burden (if available for your review)a\nYes\nNone\n✓\n\n\nUse of existing methodological filters for observational or diagnostic studies\nNo\n↑\n✓\n\n\nSelection\n\n\n\n\n\nOne reviewer screens titles and abstracts\nNo\n↑\n✓\n\n\nTitle-only screening using keyword searches based on population, intervention, and comparison (PICo)\nNo\n↑\n✓\n\n\nOne reviewer selects based on full text\nNo\n↑\n✓\n\n\nUse of dual computer monitors for selection\nNo\nNone\n✓\n\n\nData extraction\n\n\n\n\n\nOne reviewer extracts data\nNo\n↑\n✓\n\n\nOne reviewer extracts data with verification by a second reviewer\nYes\nMinimal\n✓ but evidence is limited\n\n\nData extraction limited to key characteristics, results, conflicts of interest\nYes\nNone expected\n✗\n\n\nUse of dual computer monitors for data extraction\nYes\nNone\n✓\n\n\nUse of Google Translate for data extraction from non-English trials\nNo\n↑\n✓\n\n\nNot contacting study authors to obtain missing information\nYes\nMinimal\n✓\n\n\nRisk of bias assessment\n\n\n\n\n\nLimit or omit risk of bias assessment\nNo\n↑\n✗\n\n\nNot using blinding for risk of bias assessment\nYes\nNone\n✓\n\n\nOne reviewer does risk of bias assessment\nNo\n?\n✗\n\n\nOne reviewer does risk of bias assessment with checking by a second reviewer\n?\n?\n✗\n\n\nOmit assessment of reporting/publication bias\n?\n?\n✗\n\n\nSynthesis\n\n\n\n\n\nNarrative synthesis only (no meta-analysis)\nYes\nNone\n✗\n\n\nIf data and time permit conduct a meta-analysis of one primary outcome only\nYes\nNone\n✗\n\n\nReporting\n\n\n\n\n\nInclude a methods section, even if added as an appendix\nYes\n↓\n✗\n\n\nLimit included information to the key aspects that allow a complete assessment of risk of bias (with AMSTAR 2 or ROBIS)\nYes\nNone\n✗\n\n\nConsider using a checklist to report the key aspects of the methods rather than narrative reporting\nYes\nNone\n✗\n\n\n\n\n1.1 What does this mean for ecological reviews?\nIn ecology authors of reviews (sometimes incorrectly labelled systematic reviews or meta-analysis) often take short-cuts such as only searching a single source, not assessing risk of bias or using only single reviewers (see this great paper by Haddaway et al. 2020 for a list of common problems with reviews and how to fix them).\nWhat strikes me from Haby et al. (2023) is that most of the short-cuts authors take in ecology are those that increase the risk of bias. For example, it is common to see a statement such as this in ecological reviews:\n“We conducted a search of the ISI Web of Science database* on [DATE], using the following key words…”\n\n\n\n\n\n\n*WOS is NOT a database\n\n\n\nIt is important to note that the Web Of Science platform is not a database, but rather a collection of databases. Each institution might have different subscriptions. Thus it is important that review authors list the databases that their institution has access to.\n\n\n\n\n\n\n\nSearching a single source increases the risk of bias because not all journals are indexed on each platform. A quick look at the results from two sources will show you that there are always (sometimes quite large) differences between the results of a search. For example, searching for peer-reviewed articles on Lake spawning Brown Trout in Web of Science (WOS) versus searching in Lens.org leads to a total of 1385 records, but only 69 of these are duplicated across the sources. If we only used WOS there is a risk that we might miss important evidence.\n\n#https://github.com/ESHackathon/CiteSource\n#remotes::install_github(\"ESHackathon/CiteSource\")\nlibrary(CiteSource)\n#Import citation files from a folder\ncitation_files &lt;- list.files(path = file.path(\"data\"), full.names = TRUE)\n\ncitations &lt;- read_citations(citation_files,\n                            cite_sources = c(\"lens.org\", \"WOS\"),verbose = FALSE)\n\n\n#Deduplicate citations. \nunique_citations &lt;- dedup_citations(citations)\n\n#Count number of unique and non-unique citations from different sources  \nn_unique &lt;- count_unique(unique_citations)\n\n#For each unique citation, determine which sources were present\nsource_comparison &lt;- compare_sources(unique_citations, comp_type = \"sources\")\n\n#Generate source comparison heatmap\nplot_source_overlap_heatmap(source_comparison)\n\n\n\n\nComparision of two databases (WOS & lens.org) when searching for ecological evidence\n\n\n\n\nI also found it interesting that dropping grey literature from a review can have minimal effect (although it is noted that the effect size might be overestimated) on the risk of bias. I wonder if grey literature is more important in ecology than in health? In ecology we have a large number of commissioned reports or “unpublished” reports (technical reports from NGOs etc. might be “unpublished” but still widely available on websites) that are important sources of evidence. For example, in a systematic review by Bernes et al.(2015) grey literature made up over 20% of the studies included in the synthesis. This represents a large proportion of the evidence-base in this particular case.\nHaby et al. (2023) suggest that limiting the search to English language publications has a minimal effect on the potential risk of bias. The evidence that Haby et al. (2023) base their suggestion on is from epidemiology and health technology (Morrison et al. 2012, Nussbaumer-Streit et al. 2019). In ecology a relatively large proportion of studies on the effectiveness of biodiversity conservation interventions are in a non-English language (see this great paper that addresses this issue - Amano et al. 2021).\nIgnoring grey literature or non-English studies in ecological reviews would most likely have a high potential impact on the risk of bias."
  },
  {
    "objectID": "Ecology_SR.html#conclusion",
    "href": "Ecology_SR.html#conclusion",
    "title": "Which shortcuts are really shortcuts in systematic reviews?",
    "section": "2 Conclusion",
    "text": "2 Conclusion\nEcological reviews often take short-cuts that increase the risk of bias in the reported findings - it is important that we recognise this risk and highlight it to stakeholders and policy makers.\n\n\n\n\n\n\nAcknowledgements\n\n\n\nThis blogpost was greatly improved by comments from Neal Haddaway and Ross Mounce."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dr Matthew J Grainger",
    "section": "",
    "text": "Biography\nI am an “uncertain ecologist”. My research focuses on uncertainty in conservation decision making and how best to make use of it in statistical models and in communication with stakeholders. I have a footing in evidence synthesis and a strong sideline in pheasants.\nI am currently employed as a Researcher at theNorwegian Institute for Nature Research, based in the head office in Trondheim. A list of my publications can be found here."
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "Dr Matthew J Grainger",
    "section": "Interests",
    "text": "Interests\n\nEvidence synthesis\nConservation decision making\nBiodiversity conservation\nBayesian networks\nOpen and Reproducible Science in Ecology"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Dr Matthew J Grainger",
    "section": "Education",
    "text": "Education\nPhD Zoology, 2012, University of Pretoria"
  },
  {
    "objectID": "making_missing_data_work.html",
    "href": "making_missing_data_work.html",
    "title": "Making missing data work for us",
    "section": "",
    "text": "TL;DR\n\n\n\nMissing data is a problem for the analysis of ecological data but we can use missing data theory to help fill in gaps in biodiversity monitoring data if the missingness is deliberately planned\n\n\nInspired by this paper and discussions over coffee at this year’s NINAdager (our annual work get-together) I thought I would further explore the use of planned missing data designs in ecological monitoring (I did a talk on this last year at an event on Threatened species in Norway).\n\n\nMissing data is normally a problem. Typically as ecologists we sweep missing data under the carpet by using a “complete case” approach to data analysis.\n\nIf you have ever written some code like this:\n\n# na.omit()\ndf &lt;- na.omit(df)\n\n# complete.cases()\ndf &lt;- df[complete.cases(df), ] \n\n# rowSums()\ndf &lt;- df[rowSums(is.na(df)) == 0, ] \n\n# drop_na()\ndf &lt;- df %&gt;% tidyr::drop_na()\n\nyou are removing missing data (NAs) from your dataset.\n\n\nBy throwing away potentially useful data (only including those rows without a NA in them) you reduce the information you are working with, reduce statistical power and introduce selection bias (invalidating any assumption of randomisation).\n\n\n\nThere are three broad categories of missing data, “Missing completely at random” (MCAR), “Missing at random” (MAR - a very confusing name!), “Missing not at random” (MNAR).\n\nMCAR - missingness is not related to any measured or unmeasured variables\nMAR - missingness is not random but related to other variables and can be accounted for by another complete variable\nMNAR - missingness is related to the missing data itself (there is a systematic reason why the data are missing within a particular variable)\n\nImagine that we are measuring rainfall at weather stations across Norway every year. If we randomly subsample the locations that we will measure in one particular year we will have data that is MCAR (Table 1 (b)). If the first three weather stations are on top of mountains and the weather conditions were too harsh for us to take a measurement we will have data that is MAR (missingness is related to the station number Table 1 (c)). Finally, if our rainfall measuring tool has a systematic error so that the largest amounts of rainfall are not measured we would have data that is MNAR (Table 1 (d)).\n\n\nTable 1: Missing data patterns\n\n\n\n\n(a) Complete data\n\n\nstation number\nrainfall\n\n\n\n\n1\n30\n\n\n2\n150\n\n\n3\n75\n\n\n4\n250\n\n\n5\n55\n\n\n\n\n\n\n(b) MCAR\n\n\nstation number\nrainfall\n\n\n\n\n1\n30\n\n\n2\n\n\n\n3\n\n\n\n4\n250\n\n\n5\n55\n\n\n\n\n\n\n\n\n(c) MAR\n\n\nstation number\nrainfall\n\n\n\n\n1\n\n\n\n2\n\n\n\n3\n\n\n\n4\n250\n\n\n5\n55\n\n\n\n\n\n\n(d) MNAR\n\n\nstation number\nrainfall\n\n\n\n\n1\n30\n\n\n2\n\n\n\n3\n75\n\n\n4\n\n\n\n5\n55\n\n\n\n\n\n\nWithout knowledge of what values are missing it can be impossible to identify MNAR.\n\n\n\nThe code block below shows the impact of different types of missingness on the observed relationship between two variables.\n\nlibrary(tidyverse, quietly = TRUE)\nlibrary(missMethods, quietly = TRUE)\nlibrary(palmerpenguins)\n\n# create datasets with levels missingness \n\npenguins_complete&lt;-penguins |&gt; \n  drop_na()\n# create a pattern of missingness \n#(30% missing completely at Random)\nmiss_penguins_MCAR&lt;-missMethods::delete_MCAR(penguins_complete, 0.3, \"flipper_length_mm\")\n# create a pattern of missingness with censoring\n#(missing value in flipper_length if body_mass is below 30% quantile of body_mass)\nmiss_penguins_MAR&lt;-missMethods::delete_MAR_censoring(penguins_complete, 0.3, \"flipper_length_mm\", \"body_mass_g\")\n# create a pattern of missingness with censoring \n#(missing value in flipper_length if flipper_length is below 30% quantile)\nmiss_penguins_MNAR&lt;-missMethods::delete_MNAR_censoring(penguins_complete, 0.3, \"flipper_length_mm\")\n\n\nall_data&lt;-bind_rows(\"Full\"=penguins_complete, \"MCAR\"= miss_penguins_MCAR, \"MAR\"= miss_penguins_MAR, \"MNAR\"=miss_penguins_MNAR, .id=\"Missingness\")\n\n\n## plot the missing data function\n\nMDplot&lt;-function(df_comp, df_mis, title){\n  df_comp$missX&lt;-is.na(df_mis$flipper_length_mm)\n  ggplot(data=df_comp,aes(x=flipper_length_mm,y=body_mass_g, colour=missX))+\n  geom_point(alpha=0.2)+\n  geom_smooth(method = \"lm\")+\n    labs(x=\"Flipper length (mm)\", y=\"Body mass (g)\")+\n    scale_color_discrete(name=\"Missing data?\")+\n    ggtitle(title)+\n    theme_bw()\n}\n \nMDplot(penguins_complete, miss_penguins_MCAR, title=\"MCAR\")\n\n\n\nMDplot(penguins_complete, miss_penguins_MAR, title=\"MAR\")\n\n\n\nMDplot(penguins_complete, miss_penguins_MNAR, title=\"MNAR\")\n\n\n\n\nWhere data are MCAR there is little impact on the estimate of the relationship between flipper length and body mass. However, MAR and MNAR can have large effects on the estimate.\n\n\n\nWith MCAR and MAR we can use multiple imputation techniques which generate simulated datasets to fill in the missing data. The imputed data are simulated by assessing the relationship between the variable with missingness and other complete variables. Typically several imputed datasets are produced and then combined to give a dataset with no missing data.\n\nIn addition, you can analyse covariance structures (in a regression framework). Using a Structured Equation Model (SEM) we can run a simple linear regression. Below is the code for running a normal linear model and a SEM model. You can see that the output is broadly equivalent.\n\nlibrary(lavaan)\n# we will use the Iris dataset for this example\ncomplete_model&lt;-lm(Petal.Width ~ Sepal.Length + Sepal.Width + Petal.Length, data=iris)\n\niris_MCAR&lt;-missMethods::delete_MCAR(iris, 0.3, \"Petal.Width\")\n\nmiss_model1&lt;-lm(Petal.Width ~ Sepal.Length + Sepal.Width + Petal.Length, data=iris_MCAR)\n\nWhen we use missing data we can see the difference between the regression coefficients.\n\nlibrary(stargazer, quietly = TRUE)\nstargazer(complete_model, miss_model1, \n          star.cutoffs = c(.05, .01, .001), \n  no.space = T, type = 'text')\n\n\n=====================================================================\n                                   Dependent variable:               \n                    -------------------------------------------------\n                                       Petal.Width                   \n                              (1)                      (2)           \n---------------------------------------------------------------------\nSepal.Length               -0.207***                -0.216***        \n                            (0.048)                  (0.055)         \nSepal.Width                 0.223***                 0.198***        \n                            (0.049)                  (0.057)         \nPetal.Length                0.524***                 0.533***        \n                            (0.024)                  (0.028)         \nConstant                     -0.240                   -0.137         \n                            (0.178)                  (0.217)         \n---------------------------------------------------------------------\nObservations                  150                      105           \nR2                           0.938                    0.947          \nAdjusted R2                  0.937                    0.945          \nResidual Std. Error     0.192 (df = 146)         0.187 (df = 101)    \nF Statistic         734.389*** (df = 3; 146) 599.422*** (df = 3; 101)\n=====================================================================\nNote:                                   *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n\ncomplete_model_lavv &lt;- sem('Petal.Width ~ Sepal.Length + Sepal.Width + Petal.Length', data=iris)\nsummary(complete_model_lavv)\n\nlavaan 0.6.16 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                           150\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Petal.Width ~                                       \n    Sepal.Length     -0.207    0.047   -4.422    0.000\n    Sepal.Width       0.223    0.048    4.615    0.000\n    Petal.Length      0.524    0.024   21.690    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .Petal.Width       0.036    0.004    8.660    0.000\n\nmiss_model2 &lt;- sem('Petal.Width ~ Sepal.Length + Sepal.Width + Petal.Length', data=iris_MCAR, missing=\"ML\")\nsummary(miss_model2)\n\nlavaan 0.6.16 ended normally after 28 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                           150\n  Number of missing patterns                         2\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Observed\n  Observed information based on                Hessian\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Petal.Width ~                                       \n    Sepal.Length     -0.216    0.054   -4.018    0.000\n    Sepal.Width       0.198    0.056    3.517    0.000\n    Petal.Length      0.533    0.028   19.292    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .Petal.Width      -0.137    0.213   -0.647    0.518\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .Petal.Width       0.034    0.005    7.246    0.000\n\n\nAdding the argument ‘missing = “ML”’ to the sem() function estimates a likelihood function for each row based on the variables that are present so that all the available data are used. You can see that the lm() uses only 105 observations whereas the sem() uses all 150 observations.\nMNAR is difficult to do much with as we often can not identify the process that generates the missing data pattern."
  },
  {
    "objectID": "making_missing_data_work.html#planning-monitoring-with-deliberate-missing-data",
    "href": "making_missing_data_work.html#planning-monitoring-with-deliberate-missing-data",
    "title": "Making missing data work for us",
    "section": "",
    "text": "TL;DR\n\n\n\nMissing data is a problem for the analysis of ecological data but we can use missing data theory to help fill in gaps in biodiversity monitoring data if the missingness is deliberately planned\n\n\nInspired by this paper and discussions over coffee at this year’s NINAdager (our annual work get-together) I thought I would further explore the use of planned missing data designs in ecological monitoring (I did a talk on this last year at an event on Threatened species in Norway).\n\n\nMissing data is normally a problem. Typically as ecologists we sweep missing data under the carpet by using a “complete case” approach to data analysis.\n\nIf you have ever written some code like this:\n\n# na.omit()\ndf &lt;- na.omit(df)\n\n# complete.cases()\ndf &lt;- df[complete.cases(df), ] \n\n# rowSums()\ndf &lt;- df[rowSums(is.na(df)) == 0, ] \n\n# drop_na()\ndf &lt;- df %&gt;% tidyr::drop_na()\n\nyou are removing missing data (NAs) from your dataset.\n\n\nBy throwing away potentially useful data (only including those rows without a NA in them) you reduce the information you are working with, reduce statistical power and introduce selection bias (invalidating any assumption of randomisation).\n\n\n\nThere are three broad categories of missing data, “Missing completely at random” (MCAR), “Missing at random” (MAR - a very confusing name!), “Missing not at random” (MNAR).\n\nMCAR - missingness is not related to any measured or unmeasured variables\nMAR - missingness is not random but related to other variables and can be accounted for by another complete variable\nMNAR - missingness is related to the missing data itself (there is a systematic reason why the data are missing within a particular variable)\n\nImagine that we are measuring rainfall at weather stations across Norway every year. If we randomly subsample the locations that we will measure in one particular year we will have data that is MCAR (Table 1 (b)). If the first three weather stations are on top of mountains and the weather conditions were too harsh for us to take a measurement we will have data that is MAR (missingness is related to the station number Table 1 (c)). Finally, if our rainfall measuring tool has a systematic error so that the largest amounts of rainfall are not measured we would have data that is MNAR (Table 1 (d)).\n\n\nTable 1: Missing data patterns\n\n\n\n\n(a) Complete data\n\n\nstation number\nrainfall\n\n\n\n\n1\n30\n\n\n2\n150\n\n\n3\n75\n\n\n4\n250\n\n\n5\n55\n\n\n\n\n\n\n(b) MCAR\n\n\nstation number\nrainfall\n\n\n\n\n1\n30\n\n\n2\n\n\n\n3\n\n\n\n4\n250\n\n\n5\n55\n\n\n\n\n\n\n\n\n(c) MAR\n\n\nstation number\nrainfall\n\n\n\n\n1\n\n\n\n2\n\n\n\n3\n\n\n\n4\n250\n\n\n5\n55\n\n\n\n\n\n\n(d) MNAR\n\n\nstation number\nrainfall\n\n\n\n\n1\n30\n\n\n2\n\n\n\n3\n75\n\n\n4\n\n\n\n5\n55\n\n\n\n\n\n\nWithout knowledge of what values are missing it can be impossible to identify MNAR.\n\n\n\nThe code block below shows the impact of different types of missingness on the observed relationship between two variables.\n\nlibrary(tidyverse, quietly = TRUE)\nlibrary(missMethods, quietly = TRUE)\nlibrary(palmerpenguins)\n\n# create datasets with levels missingness \n\npenguins_complete&lt;-penguins |&gt; \n  drop_na()\n# create a pattern of missingness \n#(30% missing completely at Random)\nmiss_penguins_MCAR&lt;-missMethods::delete_MCAR(penguins_complete, 0.3, \"flipper_length_mm\")\n# create a pattern of missingness with censoring\n#(missing value in flipper_length if body_mass is below 30% quantile of body_mass)\nmiss_penguins_MAR&lt;-missMethods::delete_MAR_censoring(penguins_complete, 0.3, \"flipper_length_mm\", \"body_mass_g\")\n# create a pattern of missingness with censoring \n#(missing value in flipper_length if flipper_length is below 30% quantile)\nmiss_penguins_MNAR&lt;-missMethods::delete_MNAR_censoring(penguins_complete, 0.3, \"flipper_length_mm\")\n\n\nall_data&lt;-bind_rows(\"Full\"=penguins_complete, \"MCAR\"= miss_penguins_MCAR, \"MAR\"= miss_penguins_MAR, \"MNAR\"=miss_penguins_MNAR, .id=\"Missingness\")\n\n\n## plot the missing data function\n\nMDplot&lt;-function(df_comp, df_mis, title){\n  df_comp$missX&lt;-is.na(df_mis$flipper_length_mm)\n  ggplot(data=df_comp,aes(x=flipper_length_mm,y=body_mass_g, colour=missX))+\n  geom_point(alpha=0.2)+\n  geom_smooth(method = \"lm\")+\n    labs(x=\"Flipper length (mm)\", y=\"Body mass (g)\")+\n    scale_color_discrete(name=\"Missing data?\")+\n    ggtitle(title)+\n    theme_bw()\n}\n \nMDplot(penguins_complete, miss_penguins_MCAR, title=\"MCAR\")\n\n\n\nMDplot(penguins_complete, miss_penguins_MAR, title=\"MAR\")\n\n\n\nMDplot(penguins_complete, miss_penguins_MNAR, title=\"MNAR\")\n\n\n\n\nWhere data are MCAR there is little impact on the estimate of the relationship between flipper length and body mass. However, MAR and MNAR can have large effects on the estimate.\n\n\n\nWith MCAR and MAR we can use multiple imputation techniques which generate simulated datasets to fill in the missing data. The imputed data are simulated by assessing the relationship between the variable with missingness and other complete variables. Typically several imputed datasets are produced and then combined to give a dataset with no missing data.\n\nIn addition, you can analyse covariance structures (in a regression framework). Using a Structured Equation Model (SEM) we can run a simple linear regression. Below is the code for running a normal linear model and a SEM model. You can see that the output is broadly equivalent.\n\nlibrary(lavaan)\n# we will use the Iris dataset for this example\ncomplete_model&lt;-lm(Petal.Width ~ Sepal.Length + Sepal.Width + Petal.Length, data=iris)\n\niris_MCAR&lt;-missMethods::delete_MCAR(iris, 0.3, \"Petal.Width\")\n\nmiss_model1&lt;-lm(Petal.Width ~ Sepal.Length + Sepal.Width + Petal.Length, data=iris_MCAR)\n\nWhen we use missing data we can see the difference between the regression coefficients.\n\nlibrary(stargazer, quietly = TRUE)\nstargazer(complete_model, miss_model1, \n          star.cutoffs = c(.05, .01, .001), \n  no.space = T, type = 'text')\n\n\n=====================================================================\n                                   Dependent variable:               \n                    -------------------------------------------------\n                                       Petal.Width                   \n                              (1)                      (2)           \n---------------------------------------------------------------------\nSepal.Length               -0.207***                -0.216***        \n                            (0.048)                  (0.055)         \nSepal.Width                 0.223***                 0.198***        \n                            (0.049)                  (0.057)         \nPetal.Length                0.524***                 0.533***        \n                            (0.024)                  (0.028)         \nConstant                     -0.240                   -0.137         \n                            (0.178)                  (0.217)         \n---------------------------------------------------------------------\nObservations                  150                      105           \nR2                           0.938                    0.947          \nAdjusted R2                  0.937                    0.945          \nResidual Std. Error     0.192 (df = 146)         0.187 (df = 101)    \nF Statistic         734.389*** (df = 3; 146) 599.422*** (df = 3; 101)\n=====================================================================\nNote:                                   *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n\ncomplete_model_lavv &lt;- sem('Petal.Width ~ Sepal.Length + Sepal.Width + Petal.Length', data=iris)\nsummary(complete_model_lavv)\n\nlavaan 0.6.16 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                           150\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Petal.Width ~                                       \n    Sepal.Length     -0.207    0.047   -4.422    0.000\n    Sepal.Width       0.223    0.048    4.615    0.000\n    Petal.Length      0.524    0.024   21.690    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .Petal.Width       0.036    0.004    8.660    0.000\n\nmiss_model2 &lt;- sem('Petal.Width ~ Sepal.Length + Sepal.Width + Petal.Length', data=iris_MCAR, missing=\"ML\")\nsummary(miss_model2)\n\nlavaan 0.6.16 ended normally after 28 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                           150\n  Number of missing patterns                         2\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Observed\n  Observed information based on                Hessian\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Petal.Width ~                                       \n    Sepal.Length     -0.216    0.054   -4.018    0.000\n    Sepal.Width       0.198    0.056    3.517    0.000\n    Petal.Length      0.533    0.028   19.292    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .Petal.Width      -0.137    0.213   -0.647    0.518\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .Petal.Width       0.034    0.005    7.246    0.000\n\n\nAdding the argument ‘missing = “ML”’ to the sem() function estimates a likelihood function for each row based on the variables that are present so that all the available data are used. You can see that the lm() uses only 105 observations whereas the sem() uses all 150 observations.\nMNAR is difficult to do much with as we often can not identify the process that generates the missing data pattern."
  },
  {
    "objectID": "making_missing_data_work.html#how-can-we-make-missing-data-work-for-us",
    "href": "making_missing_data_work.html#how-can-we-make-missing-data-work-for-us",
    "title": "Making missing data work for us",
    "section": "2 How can we make missing data work for us?",
    "text": "2 How can we make missing data work for us?\nPlanned missing data designs make use of missing data theory to reduce costs in monitoring. Randomly missing sampling occasions or some repeated measures on subjects creates a dataset that is MCAR. We can then use modelling or imputation techniques to fill the gaps and analyse trends in our data.\nLet’s assume we are monitoring birds at 5 locations over a number of years to assess regional trends but our budget is cut and we can only afford to visit 80% of the locations in any given year.\nWe can set up a simulation to look at the effects of imputing data.\n\n# Load mice\nlibrary(mice, quietly = TRUE)\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Simulate data: location, year, count\nlocations &lt;- rep(1:5, each = 5)  # Assuming 5 locations\nyears &lt;- rep(2009:2023, 5)  # Assuming data for 5 years\ncount &lt;- round(rpois(25, lambda = 20))  # Simulated count data\n\n# Create a dataframe\ndata &lt;- data.frame(Location = locations, Year = years, Count = count)\n\n# Introduce missingness - Missing completely at random (MCAR)\nprop_missing &lt;- 0.2  # Example: 20% missingness\nmissing_indices &lt;- sample(1:nrow(data), prop_missing * nrow(data))\ndata$Count[missing_indices] &lt;- NA\n\n# Check the structure of the data\nstr(data)\n\n'data.frame':   75 obs. of  3 variables:\n $ Location: int  1 1 1 1 1 2 2 2 2 2 ...\n $ Year    : int  2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 ...\n $ Count   : num  17 25 12 20 27 NA 14 NA 25 21 ...\n\n\nWhen we impute the missing data we use 5 replicates and then take the mean of all 5 datasets per year.\n\n# Impute missing data using MICE\nimp &lt;- mice(data, m = 5, method = 'pmm', seed = 500)\n\n\n iter imp variable\n  1   1  Count\n  1   2  Count\n  1   3  Count\n  1   4  Count\n  1   5  Count\n  2   1  Count\n  2   2  Count\n  2   3  Count\n  2   4  Count\n  2   5  Count\n  3   1  Count\n  3   2  Count\n  3   3  Count\n  3   4  Count\n  3   5  Count\n  4   1  Count\n  4   2  Count\n  4   3  Count\n  4   4  Count\n  4   5  Count\n  5   1  Count\n  5   2  Count\n  5   3  Count\n  5   4  Count\n  5   5  Count\n\n# Analyse trends and variation in the original and imputed data\n# For illustration purposes, assuming a simple trend analysis\noriginal_trend &lt;- aggregate(data$Count, by = list(data$Year), FUN = mean, na.rm = TRUE)\nnames(original_trend)&lt;-c(\"Year\",\"Count\")\nimputed_trend &lt;- complete(imp, 'long')\nimputed_trend &lt;- aggregate(Count ~ Year, data = imputed_trend, FUN = mean)\n\n# Visualization of trends in original and imputed data\nplot_data&lt;-bind_rows(\"original\"=original_trend, \"imputed\"=imputed_trend, .id=\"Trend\")\n\nplot_data |&gt; \n  ggplot(aes(Year, Count, colour=Trend))+\n  geom_point()+\n  geom_line()+\n  theme_classic()\n\n\n\n\nThe plot shows the data with imputed values (red points and line) versus the original data (blue).\n\n2.1 Caveats\nAlthough imputing data is a viable approach to resource constraints it is undoubtedly better to have real data at every step. In addition, it is important that other forms of missing data patterns are not introduced in to the data by accident."
  },
  {
    "objectID": "presentations/page-reveal.html#what-is-evidence-synthesis-technology",
    "href": "presentations/page-reveal.html#what-is-evidence-synthesis-technology",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "What is Evidence Synthesis Technology?",
    "text": "What is Evidence Synthesis Technology?\n\n“Technology is the collection of techniques, skills, methods, and processes…”\nDepends on when you ask – SR was a novel technology once!\nTools to support evidence synthesis – to overcome challenges"
  },
  {
    "objectID": "presentations/page-reveal.html#what-types-of-technology",
    "href": "presentations/page-reveal.html#what-types-of-technology",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "What types of technology",
    "text": "What types of technology\n\nComputer assistance – technology-assisted reviews\nCapacity development / training\nBetter / easier record keeping\nIncreased efficiency / transparency / rigour\nAutomation – technology-driven reviews"
  },
  {
    "objectID": "presentations/page-reveal.html#section",
    "href": "presentations/page-reveal.html#section",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "",
    "text": "Many and increasing tools available to help in systematic review\n\nBut…Often pay-walled…\n…or not supported long-term\nA lot of redundancy\nVery limited interoperability\nTools frequently not validated (or validated by the developers)"
  },
  {
    "objectID": "presentations/page-reveal.html#vienna-principles",
    "href": "presentations/page-reveal.html#vienna-principles",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "Vienna Principles",
    "text": "Vienna Principles\nPrinciples of the International Collaboration for the Automation of Systematic Reviews (ICASR). Syst Rev 7, 77 (2018)\n\nAbility to work with different tools at different stages\nTools should be interoperable\nCollaboration needed to cover all synthesis stages\nCode should be Open Source\nStandardised validation"
  },
  {
    "objectID": "presentations/page-reveal.html#what-is-the-eshackathon",
    "href": "presentations/page-reveal.html#what-is-the-eshackathon",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "What is the ESHackathon?",
    "text": "What is the ESHackathon?\nMission\nThe ESH aims to bring together interested researchers, practitioners and coders to discuss and develop new Open Source technologies for ES applications"
  },
  {
    "objectID": "presentations/page-reveal.html#origin",
    "href": "presentations/page-reveal.html#origin",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "Origin",
    "text": "Origin\n\nESH started as an open software development event in 2018\nESH has evolved into a conference, training courses and hackathons"
  },
  {
    "objectID": "presentations/page-reveal.html#hackathons",
    "href": "presentations/page-reveal.html#hackathons",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "Hackathons",
    "text": "Hackathons"
  },
  {
    "objectID": "presentations/page-reveal.html#conferences",
    "href": "presentations/page-reveal.html#conferences",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "Conferences",
    "text": "Conferences"
  },
  {
    "objectID": "presentations/page-reveal.html#training",
    "href": "presentations/page-reveal.html#training",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "Training",
    "text": "Training\nOur events page - opencollective.com/esmarconf/events"
  },
  {
    "objectID": "presentations/page-reveal.html#our-tools",
    "href": "presentations/page-reveal.html#our-tools",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "Our tools",
    "text": "Our tools"
  },
  {
    "objectID": "presentations/page-reveal.html#citationchaser",
    "href": "presentations/page-reveal.html#citationchaser",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "CitationChaser",
    "text": "CitationChaser"
  },
  {
    "objectID": "presentations/page-reveal.html#eviatlas",
    "href": "presentations/page-reveal.html#eviatlas",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "EviAtlas",
    "text": "EviAtlas"
  },
  {
    "objectID": "presentations/page-reveal.html#prisma2020",
    "href": "presentations/page-reveal.html#prisma2020",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "PRISMA2020",
    "text": "PRISMA2020"
  },
  {
    "objectID": "presentations/page-reveal.html#citesource",
    "href": "presentations/page-reveal.html#citesource",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "CiteSource",
    "text": "CiteSource"
  },
  {
    "objectID": "presentations/page-reveal.html#how-to-get-involved",
    "href": "presentations/page-reveal.html#how-to-get-involved",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "How to get involved",
    "text": "How to get involved\n\nPropose coding/discussion projects\nUse and test ESH tools, provide feedback\nApply to join a future hackathon/project\nCo-host a hackathon\nFund an ESH event (LMIC attendance)"
  },
  {
    "objectID": "presentations/page-reveal.html#join-our-community",
    "href": "presentations/page-reveal.html#join-our-community",
    "title": "Leveraging Open Source Tools for accelerating Evidence Synthesis",
    "section": "Join our community",
    "text": "Join our community"
  },
  {
    "objectID": "small_data_in_ecology.html",
    "href": "small_data_in_ecology.html",
    "title": "Small data in ecology",
    "section": "",
    "text": "TL;DR\n\n\n\n\n\n\n\n#Simulate some data with known effect\n# loop through 10000 simulations\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nttest_sim&lt;-function(nSim=1000, n=6, C_mean=12, T_mean=16, C_sd=2, T_sd=2){\nout_frame&lt;-rep(NA,nSim)\n\nfor (i in seq_along(out_frame)){\ncontrol=rnorm(n,C_mean, C_sd)\ntreatment=rnorm(n,T_mean, T_sd)\nttest&lt;-t.test(control,treatment)\nout_frame[i]&lt;-ttest$p.value\n}\n\ndata_out&lt;-data.frame(nSim=1:nSim,pValue=out_frame)\n\ndata_out |&gt; \n  ggplot(aes(pValue))+\n  geom_histogram()+\n  geom_vline(xintercept = 0.05, lty=2, colour=\"red\")+\n  ggthemes::theme_base()\n  \n}\n\nttest_sim(nSim=1000, n=6, C_mean=12, T_mean=14, C_sd=4, T_sd=4)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nAcknowledgements"
  }
]